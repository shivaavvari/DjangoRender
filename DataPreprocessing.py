# -*- coding: utf-8 -*-
"""Another copy of classifier.ipynb

Automatically generated by Colab.

Original file is located at
  https://colab.research.google.com/drive/1B31kAq_JfVdzbo9ayGaFU6VNeNEIMg27
"""

# Import necessary libraries
import kagglehub
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import (confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, 
               classification_report, f1_score, precision_score, recall_score, 
               accuracy_score, PrecisionRecallDisplay)
import matplotlib.pyplot as plt
from mlxtend.plotting import plot_confusion_matrix
import seaborn as sns
import pickle

# Download dataset
path = kagglehub.dataset_download("mlg-ulb/creditcardfraud")
print("Path to dataset files:", path)

# Load dataset
df = pd.read_csv("/root/.cache/kagglehub/datasets/mlg-ulb/creditcardfraud/versions/3/creditcard.csv", sep=",")

# Data exploration
print(df.isna().sum())
print(df.info())
print(df.dtypes)
print(df.describe())

# Plot data distributions
fig, ax = plt.subplots(nrows=6, ncols=5, figsize=(20, 10))
for col in df.columns[:-1]:
  plt.subplot(6, 5, df.columns.get_loc(col) + 1)
  df[col].plot.density()
  df[col].plot(kind='hist')
  plt.tight_layout()
plt.show()

# Pairplot and heatmap
sns.pairplot(df[df.columns[:-1]])
sns.heatmap(df.corr())

# Prepare data for training
X = df[df.columns[:-1]]
y = df[df.columns[-1]]

#Scale the Data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

#Split the Data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)

# Train RandomForestClassifier
cls = RandomForestClassifier()
cls.fit(X_train, y_train)
y_pred = cls.predict(X_test)

# Evaluate RandomForestClassifier
cm = confusion_matrix(y_test, y_pred)
cm_display = ConfusionMatrixDisplay(cm, display_labels=[0, 1])
cm_display.plot()
plt.show()

#Metrics
print(classification_report(y_test, y_pred))
print("F1 Score:", f1_score(y_test, y_pred))
print("Precision Score:", precision_score(y_test, y_pred))
print("Recall Score:", recall_score(y_test, y_pred))
print("Accuracy Score:", accuracy_score(y_test, y_pred))

y_score = cls.predict_proba(X_train)[:, 1]
print("ROC AUC Score:", roc_auc_score(y_train, y_score))

PrecisionRecallDisplay.from_estimator(cls, X_test, y_test, plot_chance_level=True)
PrecisionRecallDisplay.from_predictions(y_test, y_pred)

# Save RandomForest model
with open("model_rf.pkl", 'wb') as f:
  pickle.dump(cls, f)

# Train AdaBoostClassifier
weak_learner = DecisionTreeClassifier(max_leaf_nodes=8)
clf = AdaBoostClassifier(estimator=weak_learner, n_estimators=200, algorithm='SAMME', random_state=42)
clf.fit(X_train, y_train)
y_pred_ada = clf.predict(X_test)

# Evaluate AdaBoostClassifier
cm_ada = confusion_matrix(y_test, y_pred_ada)
cm_ada_display = ConfusionMatrixDisplay(cm_ada, display_labels=[0, 1])
cm_ada_display.plot()
plt.show()

#Metrics
print(classification_report(y_test, y_pred_ada))
print("F1 Score:", f1_score(y_test, y_pred_ada))
print("Precision Score:", precision_score(y_test, y_pred_ada))
print("Accuracy Score:", accuracy_score(y_test, y_pred_ada))

PrecisionRecallDisplay.from_estimator(clf, X_test, y_test, plot_chance_level=True)
PrecisionRecallDisplay.from_predictions(y_test, y_pred_ada)

y_score_ada = clf.predict_proba(X_train)[:, 1]
print("ROC AUC Score:", roc_auc_score(y_train, y_score_ada))

# Save AdaBoost model
with open("model_ada.pkl", 'wb') as f:
  pickle.dump(clf, f)

# Feature importances
print("RandomForest Feature Importances:", cls.feature_importances_)
print("AdaBoost Feature Importances:", clf.feature_importances_)
