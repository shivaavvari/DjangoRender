# -*- coding: utf-8 -*-
"""Another copy of Untitled16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B31kAq_JfVdzbo9ayGaFU6VNeNEIMg27
"""

# Commented out IPython magic to ensure Python compatibility.
import kagglehub
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics  import confusion_matrix ,roc_auc_score ,roc_curve, ConfusionMatrixDisplay ,RocCurveDisplay,f1_score,precision_score,recall_score,accuracy_score
import matplotlib.pyplot as plt
from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import PrecisionRecallDisplay
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report
import seaborn as sns
# %matplotlib inline


# Download latest version
#path = kagglehub.dataset_download("mlg-ulb/creditcardfraud")

print("Path to dataset files:", path)

df = pd.read_csv("/root/.cache/kagglehub/datasets/mlg-ulb/creditcardfraud/versions/3/creditcard.csv",sep=",")

df.isna().sum()
df.info()
df.dtypes
df.describe()

fig,ax = plt.subplots(nrows=6,ncols=5,figsize=(20,10))
for col in df.columns[:-1]:
  plt.subplot(6,5,df.columns.get_loc(col)+1)
  df[col].plot.density()
  df[col].plot(kind='hist')
  plt.tight_layout()
plt.show()

sns.pairplot(df[df.columns[:-1]])

sns.heatmap(df.corr())

df.corr().plot(legend=False)

"""# New Section"""

X =df[df.columns[:-1]]
y = df[df.columns[-1]]

scaler  = StandardScaler()
scaler.fit_transform(X)
X_scaled = scaler.transform(X)

X_train,X_test,y_train,y_test = train_test_split(X_scaled, y,test_size=0.33,random_state=42)

df.columns

cls = RandomForestClassifier()

cls.fit(X_train,y_train )

y_pred = cls.predict(X_test)

test = X_test[y_pred==1]
type(test)

#X_test [y_pred == 1]
#df_test = pd.DataFrame(X_test[y_pred==1],columns=df.columns[:-1])
#df_test

#df_test[df_test.index==1].to_json().replace('"0":','').replace("{",'').replace("}","")

cm = confusion_matrix(y_test,y_pred)
cm_display =ConfusionMatrixDisplay(cm,display_labels=[0,1])
cm_display.plot()
plt.show()

print(classification_report(y_test,y_pred))

f1_score(y_test,y_pred)

precision_score(y_test,y_pred)

recall_score(y_test,y_pred)

accuracy_score(y_test,y_pred)

y_score = cls.predict_proba(X_test)
y_score =y_score[:,1]
roc_auc_score(y_test,y_score)

fpr, tpr, _ = roc_curve(y_test, y_score)
roc_auc_score(y_test,y_score)
plt.title('Receiver Operating Characteristic')
plt.legend(loc='lower right')
plt.plot([0, 1], [0, 1], 'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.plot(fpr,tpr,'b',label="auc="+str(roc_auc_score(y_test,y_score)))
plt.legend(loc=4)
plt.show()

PrecisionRecallDisplay.from_estimator(cls,X_test,y_test,plot_chance_level=True)



PrecisionRecallDisplay.from_predictions(y_test,y_pred)

import pickle
with open("model_rf.pkl",'wb') as f:
  pickle.dump(cls,f)
  f.close()

weak_learner = DecisionTreeClassifier(max_leaf_nodes=8)

clf = AdaBoostClassifier(estimator=weak_learner,n_estimators=200,algorithm='SAMME',random_state=42)

clf.fit(X_train,y_train)

y_pred_ada = clf.predict(X_test)

cm_ada=confusion_matrix(y_test,y_pred_ada)

cm_ada_display =ConfusionMatrixDisplay(cm_ada,display_labels=[0,1])
cm_ada_display.plot()
plt.show()

print(classification_report(y_test,y_pred_ada))

f1_score(y_test,y_pred_ada)

precision_score(y_test,y_pred_ada)

accuracy_score(y_test,y_pred_ada )

PrecisionRecallDisplay.from_estimator(clf,X_test,y_test,plot_chance_level=True)

PrecisionRecallDisplay.from_predictions(y_test,y_pred_ada)

print(classification_report(y_test,y_pred))

y_score_ada = clf.predict_proba(X_train)[:,1]
roc_auc_score(y_train,y_score_ada)

with open("model_ada.pkl",'wb') as f:
  pickle.dump(clf,f)
  f.close()

cls.feature_importances_

clf.feature_importances_

cls

clf

